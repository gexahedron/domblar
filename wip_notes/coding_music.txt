vscode, interactive режим
	было:
	editorTextFocus && isWorkspaceTrusted && jupyter.ownsSelection && !findInputFocussed && !jupyter.webExtension && !notebookEditorFocused && !replaceInputFocussed && editorLangId == 'python'
	стало:
	editorTextFocus && isWorkspaceTrusted && !notebookEditorFocused && !replaceInputFocussed && editorLangId == 'python'

	terminal:
	editorTextFocus && !findInputFocussed && !jupyter.ownsSelection && !notebookEditorFocused && !replaceInputFocussed && editorLangId == 'python'


	editorTextFocus && isWorkspaceTrusted && jupyter.hascodecells && !editorHasSelection && !notebookEditorFocused



новый план (adlplug не рабочий, увы):
- беру за основу ADLplug
- расшифровать ручки
- изучаю банки, выбираю инструменты
- пытаюсь понять как играть (модулировать) с параметрами тембра
- можно ли сымитировать pulse-width modulation в квадратной FM волне?

ADLplug/OPNplug
- не работает parameter automatization (в .gui видно; там как будто надо string посылать)
	https://github.com/jpcima/ADLplug/issues/61
	https://github.com/jpcima/ADLplug/issues/78
+ бесплатный
+ видимо тоже стандартный
+ довольно много пресетов
!+ корректный pitch bend!
+ ест мало/средне CPU
+ есть 4op
. интерфейс чуть менее удобный чем в OPL
+ можно с клавы играть
. легко отваливается связь между интерфейсом и supercollider
	но норм работает с MIDI девайсом
	если поменять пресет
	хотя другая ручка пресетов работает
банки
	- simon the sorcerer
	- syndicate wars
		taiko drums - сойдёт за hihat
	- aces of the deep
	- Descent::Int
		квадрат - M016 LSquare


- мне кажется pitch bend не подходит
	- только в ops7 всё норм
	- тогда только surge останется?
	- или надо легато убирать как-то

- хотя возможно гораздо проще начать с dexed
- но у него кривой MPE?

https://www.youtube.com/watch?v=YqxJCu_WFuA
[adlib tracker II techno music - opl3] orbit around alpha andromedae I
kick
hihat
bass

даже так:
- точно работаю с opl3
- было бы прикольно добавить в dexed вейвформы от opl3,
	но также возникает вопрос - как это поможет?

пока что вердикт такой, что я останусь с opl3 и dexed

opl3:
+ бесплатный
+ куча пресетов
+ звук тот что надо!
+? вероятно это тоже стандарт
+ мало параметров!
+ точно ест мало CPU
?+ есть percussion режимы какие-то
- нет MPE (но это не супер страшно)
- не умеет в dx7

dexed:
+ бесплатный
+ стандартный, куча пресетов для dx7
+ кажется ест немного CPU
- нет opl3 waveforms
- звук менее жирный, чем ops7
? неправильный MPE (но это не супер страшно)

ops7:
- 1 копия жрёт 27% CPU почему-то
? не понимаю ситуацию с пресетами
	они меня даже смущают
	не знаю как сделать opl3 быстро
	не вижу перкуссии
+ умеет dx7 и opl3 одновременно
+ звук более жирный, более точный
+ (корректный) MPE!
	- с учётом того, что там шаг не в 1 полутон, а в 24

surge xt:
- сложно



ADLplug, 71 ручка
0 Master volume
1 Emulator
2 Chip count
3 4op channel count
4 [Part 1] Carrier 1 Level
5 [Part 1] Modulator 1 Level
6 [Part 1] Carrier 2 Level
7 [Part 1] Modulator 2 Level
8 [Part 2] Carrier 1 Level
9 [Part 2] Modulator 1 Level
10 [Part 2] Carrier 2 Level
11 [Part 2] Modulator 2 Level
12 [Part 3] Carrier 1 Level
13 [Part 3] Modulator 1 Level
14 [Part 3] Carrier 2 Level
15 [Part 3] Modulator 2 Level
16 [Part 4] Carrier 1 Level
17 [Part 4] Modulator 1 Level
18 [Part 4] Carrier 2 Level
19 [Part 4] Modulator 2 Level
20 [Part 5] Carrier 1 Level
21 [Part 5] Modulator 1 Level
22 [Part 5] Carrier 2 Level
23 [Part 5] Modulator 2 Level
24 [Part 6] Carrier 1 Level
25 [Part 6] Modulator 1 Level
26 [Part 6] Carrier 2 Level
27 [Part 6] Modulator 2 Level
28 [Part 7] Carrier 1 Level
29 [Part 7] Modulator 1 Level
30 [Part 7] Carrier 2 Level
31 [Part 7] Modulator 2 Level
32 [Part 8] Carrier 1 Level
33 [Part 8] Modulator 1 Level
34 [Part 8] Carrier 2 Level
35 [Part 8] Modulator 2 Level
36 [Part 9] Carrier 1 Level
37 [Part 9] Modulator 1 Level
38 [Part 9] Carrier 2 Level
39 [Part 9] Modulator 2 Level
40 [Part 10] Carrier 1 Level
41 [Part 10] Modulator 1 Level
42 [Part 10] Carrier 2 Level
43 [Part 10] Modulator 2 Level
44 [Part 11] Carrier 1 Level
45 [Part 11] Modulator 1 Level
46 [Part 11] Carrier 2 Level
47 [Part 11] Modulator 2 Level
48 [Part 12] Carrier 1 Level
49 [Part 12] Modulator 1 Level
50 [Part 12] Carrier 2 Level
51 [Part 12] Modulator 2 Level
52 [Part 13] Carrier 1 Level
53 [Part 13] Modulator 1 Level
54 [Part 13] Carrier 2 Level
55 [Part 13] Modulator 2 Level
56 [Part 14] Carrier 1 Level
57 [Part 14] Modulator 1 Level
58 [Part 14] Carrier 2 Level
59 [Part 14] Modulator 2 Level
60 [Part 15] Carrier 1 Level
61 [Part 15] Modulator 1 Level
62 [Part 15] Carrier 2 Level
63 [Part 15] Modulator 2 Level
64 [Part 16] Carrier 1 Level
65 [Part 16] Modulator 1 Level
66 [Part 16] Carrier 2 Level
67 [Part 16] Modulator 2 Level
68 Volume model
69 Deep tremolo
70 Deep vibrato


:
src/common/SurgeStorage.h
	std::atomic<bool> mapChannelToOctave; 
src/common/SurgeStorage.cpp
	ничего интересного
gui - src/surge-xt/gui/SurgeGUIEditor.cpp
src/common/SurgeSynthesizer.cpp
	void SurgeSynthesizer::playVoice(int scene, char channel, char key, char velocity, char detune,
                                 int32_t host_noteid, int16_t override_hostkey,
                                 int16_t override_hostchan)
src/common/SurgePatch.cpp
	ничего не понял, мб это для api, для внешнего управления
src/common/dsp/SurgeVoice.cpp
	float SurgeVoice::channelKeyEquvialent(float key, int channel, bool isMpeEnabled,
                                       SurgeStorage *storage, bool remapKeyForTuning)
unit tests









opl2
0 - 'carrier_wave'
1 - 'modulator_wave'
2 - 'carrier_frequency_multiplier'
3 - 'modulator_frequency_multiplier'
4 - 'carrier_attenuation'
5 - 'modulator_attenuation'
6 - 'tremolo_depth'
7 - 'vibrato_depth'
8 - 'carrier_tremolo'
9 - 'carrier_vibrato'
10 - 'carrier_sustain'
11 - 
15 - 'modulator_keyscale_rate'
18 - 'algorithm'
20 - 'carrier_attack'
21 - 'carrier_decay'
30 - 'emulator'
31 - 'percussion_mode'

'modulator_keyscale_level',
'modulator_attack',
'modulator_decay',
'carrier_velocity_sensitivity',
'modulator_velocity_sensitivity', 'carrier_sustain_level', 'carrier_keyscale_level', 'carrier_keyscale_rate', 'modulator_feedback', 'modulator_sustain', 'modulator_vibrato', 'carrier_release', modulator_sustain_level', 'modulator_tremolo', 'modulator_release', 


opl3, percussion map
http://midibox.org/forums/topic/18625-opl3-percussion-mode-map/


- pyo
	- как реализовать тут fm-алгоритмы?
	- можно ли прикрутить abs? чтоб имитировать OPL2
	я снова попробовал pyo, выглядит очень интересно, почему-то
	вроде бы всё хочется там есть
		но звук иногда кликает
		но кажется, что это лечится через правильный Envelope


Terry Riley - In C:
  - 53 кусочка + нота до для пульса (и гармоний)
  - клёвая реализация
    https://github.com/teropa/in-c
    https://teropa.info/in-c/
  - как будто бы тяжело менять гармонию правда
	(хотя см. Steve Reich)


triads:
  aug, maj, min, dim, sus2, sus4
cadences:
  authentic, plagal, deceptive, half

edo:
 9, 12, 15, 16/23 (mavila), 17, 19, 22; 26, 27



шкальность
	https://en.xen.wiki/w/Rothenberg_propriety
	https://en.xen.wiki/w/Distributional_evenness
	https://en.xen.wiki/w/Pseudo-traditional_harmonic_functions_of_octatonic_scale_degrees
	https://en.xen.wiki/w/Omnitetrachordality
	https://en.xen.wiki/w/Scale_properties_simplified


доделки по алгорейву3:
	- улучшить вывод abjad'а
		https://abjad.github.io
		https://nbviewer.jupyter.org/github/tiagoantao/abjad-ipython/blob/master/notebooks/Index.ipynb
	- разобраться с багой с ревербом
	- добавить визуалы через librosa
		https://www.youtube.com/watch?v=5LfD-hxbX0E
		https://github.com/aiXander/Realtime_PyAudio_FFT
	- закодить functional harmony
	- пофиксить луп
	- добавить SelectX в выбор EnvGen'ов
	- brighter/darker
	- добавить каденцию
	- парсер сделать более гибким, чтоб принимал параметры
	- нужно заменить pressing scales на что-то более логичное
		- zabka
		- omintetrachordality
		- MOS
		- какую-то логику, завязанную на tonnetz или JI
		- ...
	- нужно более умно использовать шкалы (какие-то характерные ноты)
	- добавить циклы (квинтовые, квартовые, секундные, терциевые)
	- добавить modulation, secondary tonic
	- добавить tritone substitution
	- добавить каноны
	- добавить контрапункт
	- избавиться от паттернов
		- сделать зацепления паттернов или какие-то более плавные переходы
	- добавить тембры
	- добавить smooth voice-leading
	- надо проработать логику для mutation
	- надо подумать про взаимодействие или зависимость голосов
	- надо добавить память по предыдущим паттернам
	- добавить abjad
	- добавить трансформации ритма


pattern языки
	panola
	tidal cycles

sonic pi
	synths:
		saw
		prophet
		tb303
		dsaw
		fm
		pulse
	Percussive
		drum_cymbal_open
		perc_bell
	threads?


алгорейв3:
	есть список голосов
	голос - набор нот
	ноты  - это несколько операций надо тоникой, внутри какой-то шкалы
	то есть каждый голос действует внутри своей шкалы
	операции:
		какие угодно
	вопрос
	есть голос
	как прикрутить аккорды?


#             if idx == 0:
#                 adds = [2-7, 4-7, 9, 13]
#                 for add in adds:
#                     n_idx2 = notes[idx] + add
#                     n2 = scale[n_idx2 % len(scale)] + edo * (n_idx2 // len(scale))
#                     freq2 = 261.6255653006 * (2 ** (n2 / edo))
#                     chiptune(b, freq2, dur=dur * mults[idx % len(mults)], amp=amps[idx % len(amps)], pan=0, env_nom=0.5, lpf=6000, target=g, add_action='head')


# scale = [0, 2, 4, 5, 7, 9, 11] # ionian / diatonic major
# scale = [0, 2, 3, 5, 7, 9, 10] # dorian
# scale = [0, 2, 3, 5, 7, 8, 10] # aeolian / natural minor
# scale = [0, 1, 3, 5, 6, 8, 10] # locrian
# scale = [0, 2, 4, 6, 7, 9, 11] # lydian
# scale = [0, 1, 3, 5, 7, 8, 10] # phrygian
# scale = [0, 2, 4, 5, 7, 9, 10] # mixolydian



# for p in scale:
#     n = p + 64
#     freq = 261.6255653006 * (2 ** ((n - 61) / 12))
#     dur = 0.2
#     chiptune(b, freq, dur=dur, pan=0, env_nom=0, target=g, add_action='head')
#     time.sleep(dur)
#     print(n)


from subprocess import check_output
def get_pid(name):
    return check_output(["pidof", name])

import psutil

process_name = "scsynth"
pid = None

for proc in psutil.process_iter():
    if process_name in proc.name():
        pid = proc.pid




алгорейв, todo:
	- закодить какие-то гармонии
		chord progressions
		например через квинтовые циклы
		или какой-то гармонический план
	- закодить мутации или формальное описание мелодии
		типа есть тема
		и есть набор операций, которые надо применить, скажем, последовательно
			чтоб получить вариацию
	- закодить ещё голоса
		полифония
	- добавить память


theseanco / co34pt

	out: output bus
	buf
	rate
	amp: amplitude
	pan: stereo panning
	для буферов - rel; у синтов тоже бывает
	для буферов - pos
	instrument
	dur
	freq: frequency
		scale
		degree
		octave
	atk: attack
	sus: sustain
	fb: phase feedback

	bplay - для буферов
	vplay:
		rel1: controls the amount of a sample played
	lplay - для лупов

	Why I don't use Pdefs
	SuperCollider as a Modular Synth
	StageLimiter abuse and 'The Guetta Effect'
	ChordSymbol

	rhythms:
		Euclidean rhythms

	riffs:
		up-down riff
		phasing
		sample stabs
		Place

	Between Pitch and Noise:
		SinOscFB
		extreme pitch values
		Chaos UGens

	Good SynthDef writing:
		freq
		out
		Envelopes

	Drones - DFM1


https://www.youtube.com/c/elifieldsteel/videos
jaxa
https://www.youtube.com/channel/UC9zUnKaXHRfF0UHtvjrXlhQ/videos
Audio Signal Processing and SuperCollider
https://www.youtube.com/playlist?list=PL1Zlv_e8Lv9g2NLtDb0X_VhIw9aR7mcJ7
Null-State Interactive Digital Art Tutorial Series 1: SuperCollider
https://www.youtube.com/playlist?list=PL9XX7ZJ9J8vfpWHAinPhlagYD67pJ5ggr

идея алгорейва:
    - композиция в духе canto ostinato
    - хочу выводить текущий паттерн где-нибудь
			получилось через music21
    - и мутировать паттерн какими-нибудь командами
			- сохранить scale, но менять модальность
				darker/brighter (можно формально посортить)
			- поменять темперацию (как найти подходящую шкалу нот?)
			- как делать вариации?


что надо к алгорейву:
	- саунд-дизайн
	- ar, kr
  - разобраться с перкуссией
  - разобраться с L-системами, гармониями, chord прогрессиями, ...


https://github.com/vitling/acid-banger
https://github.com/vitling/autotracker
https://github.com/vitling/triple-saw
+
https://theseanco.github.io/howto_co34pt_liveCode/
+
? Как писать чиптюн-музыку
https://www.youtube.com/watch?v=S4DWvPEFmZI
+
011. Ранние приёмы звукового синтеза и алгоритмической композиции на языке Python – Пётр Советов
https://www.youtube.com/watch?v=WNs8t5Yjm7o&t=216s
+
http://a-touch-of-music.blogspot.com/2013/08/algorithmic-composition-generating.html
https://github.com/shimpe/canon-generator
+
Per Norgard


трекеры:
DefleMask

https://www.youtube.com/watch?v=7zo_iFMyydE
how to algorithmic:
	pattern: timing + pitch
	1. rhythm
		clave / rhythmic key
		kick, snare, high-hat

в принципе:
вот чиптюн инструменты есть
https://www.youtube.com/watch?v=wNWFSIadAH8
код простой, звук как у Animal Style
	https://animalstyle.bandcamp.com/album/open-air
вопрос теперь:
- как сделать интересное развитие, а-ля Симеон Тен Хольт, Дебюсси (или как у тех же animal style)
- как сделать гармонии
- как добавить микротональности





SuperCollider Tutorial: 15. Composing a Piece, Part I
https://www.youtube.com/watch?v=lGs7JOOVjag
Synthesis Recipes - Chiptune
https://www.youtube.com/watch?v=-dZJuCZgH8w
Synthesis Recipe - Vangelis in Supercollider
https://www.youtube.com/watch?v=zLJ1gcw0xbc

SuperCollider_ Modular Synthesis Programming.mp4
Free standalone FM synth programmed in supercollider.mp4
Free FM8 with morphing capabilities (update).mp4


Kraftwerk's SpaceLab + SuperCollider + Vim
https://www.youtube.com/watch?v=wOjOpht5B7I





примеры на xen.wiki
https://en.xen.wiki/w/Negri
https://en.xen.wiki/w/Pajara
https://en.xen.wiki/w/Porcupine
https://en.xen.wiki/w/Superpyth
https://en.xen.wiki/w/Kleismic_family
https://en.xen.wiki/w/Orwell
https://en.xen.wiki/w/Miracle
https://en.xen.wiki/w/Semaphore_and_Godzilla
https://en.xen.wiki/w/Slendric
https://en.xen.wiki/w/Bohlen-Pierce


Definitive History of Techno
https://www.beatportal.com/features/beatports-definitive-guide-to-techno/

https://www.bestii.com/~mschulter/zest24-aaron_akj.txt
nice scale, надо попробовать в logic pro
ещё мне тут нравится момент, что соседние ноты друг от друга почти все
на расстоянии шахматного коня (кроме пары 63-204)
             49/27 ---- 49/36
             1032        534
               |          |
               |          |
28/27 ------ 14/9 ------ 7/6 ------ 7/4
 63           765        267        969
               |          |          |
               |          |          |
              4/3 ------ 1/1 ------ 3/2 ------ 9/8
              498         0         702        204
                          |          |
                          |          |
                        12/7 ------ 9/7
                         933        435


22edo
	superpyth[7], pajara[10], porcupine[7], porcupine[8], machine[6], orwell[9]
mavila[9]
	Sevish - Sea Poem https://www.youtube.com/watch?v=2p3z9YEpW1k





- поискать coincidences в дробях
		но постой, это же и есть то чем занимаются темперации!
		отчасти по-крайней мере
	например
	11/8+11/8=1100 центов
	11/9+11/9=695 центов, почти что 3/2
	и заиспользовать как модуляцию или ещё что-то


- Comparison between meantone and Rameau temperaments
очень клёвая тема!


80s music production:
- gated reverb on drums
- default synth patches - yamaha DX7, korg m1
- Rompler and FM synths/tone modules
- chorus on guitars and bass, flanging
- move towards clean transformerless signal paths
- big cathedral reverbs
- Linn Drum
- SSL console, Lexicon reverbs and delays, AMS reverbs and harmonizers, CMI fairlight (and sampling in general), DX7, analog poly synths like the Jupiter 8, drum machines like LinnDrum, DMX, and Simmons SDS5/7 & sequencer



harpsichord
https://freesound.org/people/pjcohen/packs/21464/



- изучить timbre spatialization
	типа берём fft
	и создаём зависимость pan от fft, или наоборот

- попробовать баха в:
  We will focus on microtonal solfège and theory: several MOS scales as subscales to 22-EDO, e.g.
		superpyth[7], pajara[10], porcupine[7], porcupine[8], machine[6], orwell[9]
		http://www.schoenberg.ee/index2.php/index.php?sitesig=SB&page=SB_030_Tegevus&subpage=2021_Gradus_ad_Parnassum
		https://drive.google.com/file/d/10IEN7dQthyN0Do1vWeUOfwQiYxrpH45t/view
		https://drive.google.com/drive/folders/1lvbivz-zcfIhQf1Xs8IkfVhXB9snXfYe?fbclid=IwAR2ndQmTcxb3oYX4q73IeJovchEVQChC37_HgCs_i5db614b8z8nQAMe5Uo


- Vicentino 31-tet

sunvox
https://gist.github.com/gldnspud/38b5d2a94d524f9c743a69de210501e3
https://github.com/metrasynth/gallery
https://solar-sails.readthedocs.io/en/latest/readme.html

1bit music
https://habr.com/ru/post/348036/
https://habr.com/ru/post/348192/


surge
https://github.com/surge-synthesizer/surge
https://github.com/surge-synthesizer/surge-python/blob/main/api-tutorial/01%20Create%20Surge%20and%20Play%20a%20Note.ipynb



- собрать всё по музыке в один файл
- закодить идею:
	voice leading produces harmony
	widespread rock harmonic routines arise out of the desire to harmonize descending melodies.
- закодить прелюдию баха
- выложить код и аудио по аппроксимациям
	- код надо причесать сначала всё же
- заценить biophilia
- сконвертировать прогрессии аккордов в JI
- поизучать прогрессии в других системах (porcupine)
- разобраться с OSC и Logic Pro
- глянуть папку bach math
- глянуть папку algorithmic tension-release
- изучить - аудио, арт и интерактивность в вебе
		для микротональностей
		и вообще, например
		хочу закодить сайт про статью harmony logic
			про каденции, например

план:
	- сгенерить набор нот
	- сгенерить мелодию в этом наборе (какой-нибудь перебор)
		- и ритм
	- сгенерить рандомное бинарное дерево
		которое отвечает за разбивку произведения на подструктуры
		- и навесить на вершины операции
	- сгенерить всю мелодию
		- было бы клёво уметь логично завершать произведение

	а что если взять мой генератор JI аккордов
		и сделать ему зависимость по 2 нотам?
		или разбивать скажем на блоки по 4 такта
		и в каждом блоке выбирать пару простых, по которым мы будем смещаться



==============================
==============================


Mini challenge: write a modulating Canon.
Recently I stumbled over this super cute Canon, that does descend chromatically with each iteration.
This is achieved by using a common chord modulation: Of the original minor key Gmin, the V chord D is reinterpreted as bVI chord of the new key F#min, so you can then follow it with the V chord of F#min next, C#.


What is the purpose of the first four chords, I ii V I? Why doesn't it go anywhere?
Then what chords are used to make the progression actually get somewhere?


Baroque composers thought in terms of figured bass. To them the bass note was foundational and they thought of the structure above it in terms of the intervals of the notes from the bass. This was because they were trained in using and playing from a figured bass.


анализ
bach
	https://andrewhennington.wordpress.com/2015/10/22/j-s-bach-prelude-no-1-in-c-major-bwv-846/
	https://www.teoria.com/en/articles/2017/BWV846/01.php
		I          - ii_2^4           - V_5^6   - I (основная тема)
			основа темы - квинтовый круг
		vi^6       - V_2^4/V          - V^6     - I_2^4
			?
		vi^7       - V^7/V            - V       - . (выпало)
			?
		vii_3^4/ii - ii^6             - vii_3^4 - I^6
			?
		.          - (IV_2^4 - ii^7)  - V^7     - I
			похоже на квинтовый круг
		V^7/IV     - (IV^7 - vii^7/V) - vii_2^4 - .
			?
		дальше dominant pedal, 24-31
			V^7 - V+I - V^7 - V^7 - vii^7/V - V+I - V^7 - V^7
    V^7/IV     - IV               - V^7     - I

I, ii, iii, IV, V, vi, vii[^o]

квинтовый круг:
I - IV - vii0 - iii - vi - ii - V - I
отсюда же вытаскивается прогрессия I - IV - V - I


бах, каноны
	https://www.projectawe.org/blog/2015/9/1/the-13th-canon-portrait-of-js-bach



debussy
	debussy arabesque analysis
	https://www.reddit.com/r/musictheory/comments/dfq47g/how_to_get_that_ethereal_sound_like_debussy_and/
moonlight sonata
	https://www.youtube.com/watch?v=eNBm9wD9zg0


	SynthDef(\marimba, {arg out=0, amp=0.1, t_trig=1, freq=100, rq=0.006;
		var env, signal;
		var rho, theta, b1, b2;
		b1 = 1.987 * 0.9889999999 * cos(0.09);
		b2 = 0.998057.neg;
		signal = SOS.ar(K2A.ar(t_trig), 0.3, 0.0, 0.0, b1, b2);
		signal = RHPF.ar(signal*0.8, freq, rq) + DelayC.ar(RHPF.ar(signal*0.9, freq*0.99999, rq*0.\
	999), 0.02, 0.01223);
		signal = Decay2.ar(signal, 0.4, 0.3, signal);
		DetectSilence.ar(signal, 0.01, doneAction:2);
		Out.ar(out, signal*(amp*0.4)!2);
	}).add;

	Pbind(
		\instrument, \marimba,
		\midinote, Prand([[1,5], 2, [3, 5], 7, 9, 3], inf) + 48,
		\dur, 0.2
	).play;

	// Or perhaps
	SynthDef(\wood, {arg out=0, amp=0.3, pan=0, sustain=0.5, t_trig=1, freq=100, rq=0.06;
		var env, signal;
		var rho, theta, b1, b2;
		b1 = 2.0 * 0.97576 * cos(0.161447);
		b2 = 0.9757.squared.neg;
		signal = SOS.ar(K2A.ar(t_trig), 1.0, 0.0, 0.0, b1, b2);
		signal = Decay2.ar(signal, 0.4, 0.8, signal);
		signal = Limiter.ar(Resonz.ar(signal, freq, rq*0.5), 0.9);
		env = EnvGen.kr(Env.perc(0.00001, sustain, amp), doneAction:2);
		Out.ar(out, Pan2.ar(signal, pan)*env);
	}).add;

	Pbind(
		\instrument, \wood,
		\midinote, Prand([[1,5], 2, [3, 5], 7, 9, 3], inf) + 48,
		\dur, 0.2
	).play;


bebop scale
https://music.stackexchange.com/questions/108314/harmonizing-the-bebop-major-diminished-sixth-scale-barry-harris

partch
https://www.youtube.com/watch?v=I4Cp8XP66JM
harry partch "the rose" sheet
https://www.reddit.com/r/classicalmusic/comments/5omvcu/the_rose_by_harry_partch_a_freight_train_hopping/
https://www.youtube.com/watch?v=ZdQorwcpy3Q
https://www.youtube.com/watch?v=mmBYno83vig


https://www.youtube.com/c/WalkThatBass/videos


Karplus-Strong
https://flothesof.github.io/Karplus-Strong-algorithm-Python.html



SongMASS: Automatic Song Writing with Masked Sequence to Sequence Pre-training
https://musicgeneration.github.io/SongMASS/
google: gpt2 music

https://www.coursera.org/learn/melodic-forms-simple-harmony/lecture/CLN89/an-utterly-different-aesthetic-part-1
https://music.tutsplus.com/tutorials/the-contemporary-musicians-guide-to-counterpoint--audio-4630
https://music.tutsplus.com/tutorials/an-introduction-to-cadences--audio-3325
artificially generated music
	https://dmitri.mycpanel.princeton.edu/robotsexplanation.html
Primitive Hierarchical Processes and the Structure of a Single Note
	http://davesmey.com/papers/primitive/primitive.php






https://www.reddit.com/r/musictheory/comments/fej0m9/song_analysis/
If this is your goal, you should start with theory and then test your understanding by doing analysis. David Temperley's The Musical Language of Rock, while not my favorite text, collects numerous current methodologies. Here are some other works that might be helpful:
Trevor de Clercq's dissertation, Sections and Successions in Successful Songs: A Prototype Approach to Form in Rock Music
Drew Nobile - Harmonic Function in Rock Music: A Syntactical Approach
Drew Nobile - Counterpoint in Rock Music: Unpacking the "Melodic-Harmonic Divorce"
Trevor de Clercq - The Harmonic-Bass Divorce in Rock Music
Mark Spicer - (Ac)cumulative Form in Pop-Rock Music
MTO 17/3, Special Issue: (Per)Form in(g) Rock
David Heetderks - Hipster Harmony: The Hybrid Syntax of Seventh Chords in Post-Millennial Rock
Nicole Biamonte - Triadic Modal and Pentatonic Patterns in Rock Music
Nicole Biamonte - Formal Functions of Metric Dissonance in Rock Music
Walter Everett - Making Sense of Rock’s Tonal Systems
Christopher Endrinal's dissertation, Form and Style in the Music of U2
Drew Nobile - Form and Voice Leading in Early Beatles Songs
Shaughn O'Donnell - 'On the Path': Tracing Tonal Coherence in The Dark Side of the Moon
Mark Butler - Turning the Beat Around: Reinterpretation, Metrical Dissonance, and Asymmetry in Electronic Dance Music
Kyle Adams - On the Metrical Techniques of Flow in Rap Music
Kate Heidemann - A System for Describing Vocal Timbre in Popular Song



These motific building blocks are not simply repeated verbatim throughout a piece of music; rather, as in the example of figure 1, the fragments are transformed in a musically logical way.
This logic demands
	coherent harmony,
	melody and phrasing structure;
		this in turns requires such non-trivial motif transformations as
			transposition,
			diatonic shifting,
			deletion,
			insertion of passing tones,
			truncation,
			etc.




AudioSculpt
Spat
pure-data
	https://github.com/porres/Live-Electronics-Tutorial/releases/tag/v1.0-beta-33
Scala


https://cycling74.com/articles/an-interview-with-george-lewis-and-damon-holzborn-part-1
https://cycling74.com/articles/an-interview-with-george-lewis-and-damon-holzborn-part-2
https://blog.oup.com/2016/10/computer-art-digital-production/



Advanced Jazz Harmony Without the Indigestion (ft. June Lee's Pedal Point Etude)
https://www.youtube.com/watch?v=jjC7dpI1Zl8
Variation: 14 Ways to Compose with One Idea
https://www.youtube.com/watch?v=fJfvFqT9XV8



On a Language of Musical Thought
https://medium.com/the-sound-of-ai/on-a-language-of-musical-thought-d5ab41c77ebd
On a Language of Musical Thought [Part 2]
https://medium.com/the-sound-of-ai/on-a-language-of-musical-thought-part-2-99eb968a7a77
What Makes a Great Melody? 7 Lessons Learned from UNDERTALE
https://medium.com/the-sound-of-ai/what-makes-a-great-melody-7-lessons-learned-from-undertale-75c776054445
A Beautiful Song – The Adaptive Music of NieR: Automata
https://medium.com/the-sound-of-ai/a-beautiful-song-the-adaptive-music-of-nier-automata-4b29e5d7f2f3

music analysis
https://www.youtube.com/user/DavidBennettThomas/videos






Machine learning research that matters for music creation: A case study
Algorithmic Composition: Computational Thinking
A Study on the Perception of Algorithmic Composition Music
Algorithmic compositions based on discovered musical patterns
Investigating affect in algorithmic composition systems



Pure Data
This is very informal documentation for the Smeck guitar processing patch described in the paper, "Patch for guitar" (available as HTML or PDF ) presented at the second Pd convention in Montreal, 2007.
http://msp.ucsd.edu/smeck/latest/doc/index.htm
Pure Data finished patch from lecture
https://www.youtube.com/watch?v=aLIqXrJqPqo
Pure Data guest lecture for Tulane University
https://www.youtube.com/watch?v=2_P7MVQnmZk&t=381s



rhythms
https://github.com/fredbru/jaki


google: ismir timbre deep learning

google: automatic melody generation github
https://github.com/HajimeKawahara/autobop/wiki
https://github.com/bearpelican/musicautobot

ness
https://fancyyyyy.bandcamp.com/album/brass-cultures
http://www.ness.music.ed.ac.uk/music-and-tools/releases

pachet
music markov constraints pachet github
"pachet" "flow machines" github
Assisted music creation with Flow Machines: towards new categories of new
	https://arxiv.org/pdf/2006.09232v2.pdf
https://www.helloworldalbum.net/track-by-track/
https://skyggewithai.bandcamp.com/album/hello-world
https://github.com/kastnerkyle/pachet_experiments
Pachet, F., Roy, P.: Non-conformant harmonization: the real book in the style of Take 6


MusPy is an open source Python library for symbolic music generation. It provides essential tools for developing a music generation system, including dataset management, data I/O, data preprocessing and model evaluation.
https://github.com/salu133445/muspy


Turning BASS into violin (using AI)
https://www.youtube.com/watch?v=cIX4y22NWWc


изучить архитектуры
	SampleRNN
	WaveNet
	MuseNet



MuseNet
https://openai.com/blog/musenet/

https://magenta.github.io/listen-to-transformer/

ismir
deep learning ismir
https://program.ismir2020.net/industry_dolby.html
https://www.ismir2020.net/tutorials/
http://www.jordipons.me/top-10-ismir-papers-my-selection/
https://jongpillee.github.io/about.html
http://ismir.net/resources/tutorials/



audio mosaicing
http://labrosa.ee.columbia.edu/hamr_ismir2014/proceedings/doku.php?id=audio_mosaicing
И оно же в причесанном виде и со статьей:
https://www.audiolabs-erlangen.de/resources/MIR/2015-ISMIR-LetItBee
http://www.mirlab.org/conference_papers/International_Conference/ISMIR%202015/website/articles_splitted/13_Paper.pdf


А есть ли успешные попытки писать музыку не через волны-фурье, а через ноты? Грубо говоря, как текст из слов.
Вот, например:
https://highnoongmt.wordpress.com/2015/08/07/the-infinite-irish-trad-session/


https://magenta.tensorflow.org/music-transformer


"WaveRNN" music generation
melgan music generation
gansynth music generation
MelNet music generation
WaveGlow
WaveFlow: A Compact Flow-based Model for Raw Audio
WaveNet (QPNet) music generation
WaveGrad
DiffWave
WaveGAN

jukebox
unagan

https://github.com/apfalz/audio_lstm
http://apfalz.github.io/rnn/rnn_demo.html


структурная генерация текстов:
	Top-Down Tree Structured Text Generation
	to google: deep learning attention grammar generation
	A Grammar-Based Structural CNN Decoder for Code Generation
	Neural Text Generation: A Practical Guide

	urrng:
	https://www.aclweb.org/anthology/N19-1114.pdf
	https://github.com/harvardnlp/urnng
	https://scholar.google.com/scholar?newwindow=1&client=safari&rls=en&sxsrf=ALeKk03vTJKG3j-hnfxw-VlrZzDsIB6w-A:1604312725927&gs_lcp=CgZwc3ktYWIQAzoECAAQEzoGCAAQDRAeOgYIABAIEB5QvBxYpE9g5lZoAHAAeACAAbkBiAGEG5IBBDAuMjeYAQCgAQKgAQGqAQdnd3Mtd2l6wAEB&uact=5&um=1&ie=UTF-8&lr&cites=3376867643401134370
	Scalable Syntax-Aware Language Models Using Knowledge Distillation
	https://arxiv.org/pdf/1906.06438.pdf
	Tree Transformer: Integrating Tree Structures into Self-Attention
	https://arxiv.org/pdf/1909.06639.pdf
	PaLM: A Hybrid Parser and Language Model
	https://arxiv.org/pdf/1909.02134.pdf
	Compound Probabilistic Context-Free Grammars for Grammar Induction
	https://arxiv.org/pdf/1906.10225.pdf
	On Tree-Based Neural Sentence Modeling
	https://ttic.uchicago.edu/~freda/paper/shi2018tree.pdf
	Human-like Natural Language Generation Using Monte Carlo Tree Search
	https://www.aclweb.org/anthology/W16-5502.pdf
	Syntactic Structure from Deep Learning
	https://tallinzen.net/media/papers/linzen_baroni_2020_annual_reviews_linguistics.pdf
	Reinforcement learning of minimalist grammars
	https://arxiv.org/pdf/2005.00359.pdf

	google: generative unsupervised semantic parsing
	Text Generation from Knowledge Graphs with Graph Transformers
	https://www.aclweb.org/anthology/N19-1238.pdf
	Unsupervised Person Image Generation with Semantic Parsing Transformation
	http://39.96.165.147/Pub%20Files/2019/ssj_cvpr19.pdf
	generative markov logic models

	ChemBERTa: Large-Scale Self-Supervised Pretraining for Molecular Property Prediction
	https://arxiv.org/pdf/2010.09885.pdf


MUSIC TRANSFORMER:
GENERATING MUSIC WITH LONG-TERM STRUCTURE
https://openreview.net/pdf?id=rJe4ShAcF7
https://storage.googleapis.com/magentadata/papers/music-transformer/index.html


Generating music in the waveform domain
https://benanne.github.io/2020/03/24/audio-generation.html


chord progressions:
google: Cube Dance' graph of Douthett and Steinbach


arvo part, generative music:
http://žurnalai.lmta.lt/wp-content/uploads/2014/11lietuvos-muzikologija15-8.pdf
https://digital.library.unt.edu/ark:/67531/metadc801959/m2/1/high_res_d/dissertation.pdf
https://read.dukeupress.edu/journal-of-music-theory/article-abstract/55/1/1/94353/Transformational-Aspects-of-Arvo-Part-s

ALL ABOUT MUSICAL SCALES - A COMPLETE GUIDE!!!
https://www.youtube.com/watch?v=Vq2xt2D3e3E

Successes and Failures of Neural Network Models of Hearing
https://www.youtube.com/watch?v=zrLulOXryVA&feature=emb_title

ddsp alternative:
Hierarchical Timbre-Painting and Articulation Generation
https://arxiv.org/abs/2008.13095
https://github.com/mosheman5/timbre_painting
https://colab.research.google.com/github/mosheman5/timbre_painting/blob/master/timbre_painting.ipynb
https://www.reddit.com/r/MachineLearning/comments/jnixdf/r_hierarchical_timbrepainting_and_articulation/



COMPOSING WITH PROCESS: PERSPECTIVES ON GENERATIVE AND SYSTEMS MUSIC #1.1
https://rwm.macba.cat/en/research/composing-process-perspectives-generative-and-systems-music-11-continue






dmitri tymoczko
Tonality: An Owner's Maual
https://dmitri.mycpanel.princeton.edu/tonality-an-owners-manual.html
Contents

CHAPTER 1. Implicit musical knowledge
1. Geometry
2. Philosophy
3. Statistics
4. Schema
5. Outline

Prelude: circular voice-leading space
CHAPTER 2. Analysis: rock logic
1. The melodic principle
2. The harmonic principle
3. A first song family
4. Two more families
5. Shepard-tone passacaglias
6. Minor triads and other trichords
7. A fourth song family
8. Other modalities
9. Function and retrofunction
10. Continuity or reinvention?

Prelude: repetition reconsidered
CHAPTER 3. Counterpoint: canon and configuration
1. The imperfect system
2. Canon and crossing
3. Other intervals
4. The Tinctoris Transform
5. Three voices and the circle of diatonic triads
6. A few moments from Chopin
7. Three voices, multiple chord types
8. Four-voice triadic counterpoint
9. Seventh chords
10. Envoi

Prelude: three varieties of analytical reduction
CHAPTER 4. Counterpoint: the nonharmonic system
1. The first practice and the SNAP system
2. Schoenberg’s critique
3. Monteverdi’s “Ohimè”
4. The standardized second practice
5. The end of the nonharmonic system
6. After nonharmonicity

Prelude: functional and scale-degree analysis
CHAPTER 5. Harmony: origins
1. The logical structure of simple functionality
2. Similarities and differences
3. Origin and meaning
4. Harmony and polyphony
5. The Pope Marcellus Kyrie
6. A broader perspective
7. Modal homogenization, briefly
8. “I Cannot Follow”

Prelude: could the Martians understand our music?
CHAPTER 6. Harmony: progressions
1. Harmonic cycles: preliminaries
2. A theory of harmonic cycles
3. Fauxbourdon
4. Transpositional sequences
5. Contrary sequences
6. Near and partial sequences
7. Melody and harmony
8. Bach the dualist

Prelude: hearing and hearing-as
CHAPTER 7. Harmony: hierarchy
1. Melodic structure
2. An expanded vocabulary of melodic templates
3. Prolongation, inversion, and cadential weight.
4. Simple harmonic recursion
5. Harmonic recursion at the phrasal level
6. Harmonic recursion at the level of the piece: major keys and scales
7. Harmonic recursion at the level of the piece: minor keys
8. Modulatory schemas
9. Phrase logic
10. Formenlehre

Prelude: why Beethoven?
CHAPTER 8. Analysis: Beethoven Theorist
1. Meet the Ludwig
2. From Schema to Flow
3. The Tempest
4. The Fifth
5. The Pastorale Sonata
6. Schubert’s Quartett-Satz
7. The prelude to Lohengrin

9. Conclusion

10. Appendix A: Fundamentals of voice-leading geometry

11. Appendix B: Music theory and corpus analysis





tonal pitch space
https://books.google.ru/books?id=qZXQWvXniiUC&hl=ru&source=gbs_book_other_versions
	есть статья tonal pitch space
1 THEORETICAL FOUNDATIONS
2 DIATONIC SPACE
3 PATHS IN PITCH SPACE
4 TONAL TENSION AND ATTRACTION
  статья MODELING TONAL TENSION
  https://static1.squarespace.com/static/58812885e6f2e1da63d1291b/t/589177f3f7e0abd41ebd1e75/1485928480330/Modeling+Tonal+Tension.pdf
5 PROLONGATIONAL FUNCTIONS
6 CHROMATIC TONAL SPACES
7 PROLONGATIONS IN CHROMATIC SPACES
8 ATONAL STRUCTURES




Halley Young
I am interested in compiling a list of different definitions of scales in EDO, as it seems there are a lot of them - for instance:
1. scale as a hierarchy, where higher elements are more expected and/or more likely to occur in the context of large intervals (lerdahl)
	(1) isn't really Lerdahl---the numerical aspect of the hierarchy came from Krumhansl. Interestingly, she deals with quarter-tones in a 12edo study, and finds that they're understood as averages of adjacent 12edo notes.
2. scale as an assignment of pitch class to another number called degree, which may be associated with some (either original or canonical) associated behaviors of those degrees (harrison)
3. scale as a metric of distance between pitch classes (tymoczko)
4.scale as simply a set of pitches which don't have to be treated as "chromatic notes", and hence can be used in many contexts where non-scale notes cannot (russell)
5. scale as determining the set of roots that chords in the given context can have (I've been told this is a Bruckner idiom).
6. scale as the mode, which has various topological/DFT properties, plus the root (I'm gonna give this one credit to Jason Yust, who may or may not accept it)
7. Amelia Huff
You’re forgetting my favorite! 😁
Scale which is a literal macroharmonic chord entity. A sound mass with a gestalt identity. Scale is the motherchord and all other chords are just reductions of this sound mass.
8. Kraig Grady
Scale also as a constant structure, with certain cyclical identities. where any interval when it occurs is always subtended by the same number of scale steps
9. Noah Kahrs
There's also the Schenker-Jonas thing of having a scale being a way of filling in the space opened up by a triad.
10. Mike Battaglia
I'm not sure where I first read this from (Huron?), but probably the all-encompassing definition of a scale would be a set of notes and a probability distribution on them. That is, a scale is a random variable, with a certain probability that each note will be played. This generalizes Krumhansl's definition.
11. Joseph Monzo
A scale is the set of source pitches from which a composer forms the melodies and harmonies of a composition. (Leonard Bernstein)


It's not clear how you're distinguishing scale from mode---in formal scale theory I'm more used to scale just being the unordered collection, and mode being a specific order (as in Clampitt/Noll 2011).
	Halley Young
	Noah Kahrs yes, you're right that I'm including both definitions which take into account order and which don't.
Many of these definitions precede or don't require EDOs. I.e. the diatonic collection is millenia older than anyone being able to calculate 2^(1/12).



Rewrite rules:
  Prolongation

  Diatonic preparation
  Dominant preparation
  Plagal preparation

  Modulation
  Mode change

  Diatonic substitution
  Dominant substitution

Termination rules:
  7th chord termination
  ...

Turnaround problem


# hierarchies
# Lerdahl and Jackendoff:
# 1. grouping structure
# 2. metrical structure
# 3. time-span reduction
# 4. prolongational reduction
# more
# hierarchies
# 5. timbral
# 6. tonal pitch space (?)
# 7. consonances and dissonances (soft, hard)




# As summarized very effectively by the authors of (Moss, et al. 2019), tonal harmony compositions share four essential features: centricity, referentiality, directedness, and hierarchy.
# 1. centricity, the observation that tonal harmony is governed by a few central chords (Neuwirth, et al. 2018)
# 2. referentiality introduces the idea that chords occur within a hierarchical structure at both global (among tonal regions) and local level (between individual chords); (Schoenberg 1969) (Lerdahl and Jackendoff 1983) (Rorhmeir 2011) (D. Tymoczko, Root Motion, Function, Scale-degree: A Grammar for Elementary Tonal Harmony 2003). Chords do not occur in random order, but they are introduced following syntactical rules
# 3. directedness, is the preference for asymmetric chord progressions in tonal music: (Hedges and Rohrmeier 2011) it has direct implications in the formation of listening expectations and the directionality of chord progressions towards a build-up on expectation and release
# 4. hierarchy involves the construction of hierarchical relationships at every level of the composition, from the locality of chords to the global organization of tonal regions and keys within a single piece (Schenker 1954)


Ещё одна возможная иерархия или самоорганизация
	в создании самого инструмента, в том как формируется тембр
	Generator
	resonator
	synchronization

При генеративном подходе стоит задуматься о том, что
	возможно хочется достичь ambiguity в парсинге дерева
	чтоб сгенерированную музыку можно было проанализировать многими разными деревьями

Lerdahl interview:
	Our own contributions in the area of music cognition include preference rules (GTTM) and
	operations on tonal basic spaces (TPS).

	Yes. The model would take as input a musical surface — that is, pitches, rhythms,
	and dynamics, idealized away from the complications and vagaries of the audio
	signal. It would give as output a set of “preferred” structures that listeners infer from
	the surface. Specifically, it would assign grouping and metrical structures, time-span
	segmentation, the pitch space projected by the music, the location of pitches and
	chords in the space as the music unfolds, time-span and prolongational reduction,
	tonal attractions, and degrees of tonal tension and relaxation.

	For music that focuses on timbral processes, such as much
	electronic and spectral music, this program of research would require the full
	development of a perceptual-cognitive theory of musical timbre. It is regrettable that
	research in this area has declined after several incomplete attempts in the 1970s and
	1980s (
		Cogan & Escot, 1976;
			Cogan, R., & P. Escot (1976). Sonic design: the nature of sound and music.
		Grey, 1977;
			Grey, J. M. (1977). Multidimensional perceptual scaling of musical timbres.
		Wessel, 1979;
			Wessel, D. (1979). Timbre space as a musical control structure.
		Slawson, 1981;
			Slawson, W. (1981). The color of sound: a theoretical study in muscal timbre.
		Lerdahl, 1987
			Lerdahl, F. (1987). Timbral hierarchies.
	). A genuine theory of this kind would not only help explain how listeners make
	sense of electronic and spectral music but would also be useful for composers.


gttm:
1. grouping structure
2. metrical structure
1,2. => 3. time-span segmentation
4. stability conditions
3,4. => 5. time-span reduction
4,5. => 6. prolongational reduction
	включает ещё interaction principle

3 crucial stages:
	First is the distinction between grouping and meter.
	Second is the notion of preference-rule systems.
	Third is the interaction principle

tps:
1. pitch-space distances
1. => 2. tonic finding
3. sensory dissonance
1,2,3. => 4. time-span reduction
1,4. => 5. prolongational reduction

gttm/tps: нужно скомбинировать
добавляются
	spatial/geometric representations
	prolongational good form / principle of shortest path
	harmonic function
	attraction model
	tension model
что без входных зависимостей:
	grouping structure
	metrical structure
	pitch-space distances
	sensory dissonance
	prolongational good form

какие есть правила:
  well-formedness rules
  transformational rules
  preference rules
  algorithmic rules

tonic -> departure -> tension -> cadential preparation -> cadence



https://salu133445.github.io/ismir2019tutorial/
https://liuhaumin.github.io/LeadsheetArrangement/model
https://colab.research.google.com/drive/1Cnq9z3QvxIsVntlXKjPjbwttxeDH47Xl
https://colab.research.google.com/drive/1WrFtqo5LW8QfhiuhHmge9QLexWwS2BcM#scrollTo=4ukfh1dxIsDw
https://salu133445.github.io/ismir2019tutorial/pdf/ismir2019-tutorial-slides.pdf
https://colab.research.google.com/drive/1Cnq9z3QvxIsVntlXKjPjbwttxeDH47Xl
https://colab.research.google.com/drive/1WrFtqo5LW8QfhiuhHmge9QLexWwS2BcM#scrollTo=ms8dVTzkrNy2
https://zenodo.org/record/3529714#.X5qnTSpzDUr
http://archives.ismir.net/ismir2019/paper/000083.pdf
https://github.com/chrisdonahue/nesmdb
https://github.com/chrisdonahue/LakhNES/blob/master/model/mem_transformer.py

https://www.stevenwaterman.uk/musetree/


computer simulation of musical creativity
music metacreation workshops
joint conference on ai music creativity
journal creative music system
	https://www.jcms.org.uk/issues/



https://www2.slideshare.net/affige/automatic-music-composition-with-transformers-jan-2021



про саунд арт
	Ту роль, которую в западных музеях играет категоризация и классификация, в устных культурах играет звук. [ 33 ] В своем знаковом эссе «Эхо-камера доктора Сатаны» (Dr. Satan’s Echo Chamber) Луис Чуде-Сокей говорит, что в случае культур черной Африки и диаспор «звук» мог бы стать центральным понятием для осмысления их производительных сил и функционирования. [ 34 ] Чуде-Сокей исходит от идеи «слово-звука», существующей в растафарианской концепции: «Звук становится своим собственным полем знаний, дискурса, политики, где слово обязательно связано с культурной специфичностью, которая непременно должна считаться с другим, со звуком. В свою очередь, <…> звук должен бороться с последствиями и воздействиями своего эхо и культурных практик тех, кто находится на достаточном расстоянии, чтобы производить собственные локальные смыслы из этого эхо прежде, чем оно замрет и исчезнет, проглоченное бесконечностью». [ 35 ] Эхо-камера – метафора движения звука, диффузии знания через звуковые волны, связывающие места и культуры. В частности Чуде-Сокей говорит о культуре регги и музыки даб, появившихся на Ямайке в 1960–1970-е годы. Основанный на эхе и реверберации, даб стал способом распространить звук и ту информацию, которая в нем содержалась. Тот же самый принцип лежит в основе устных культур, как наглядно показывает Сафи Фай в своей киноленте. Историю рассказывает maam, старейшина, а потом полифоническим эхом отражают мальчишки. Такой способ повествования и передачи знания эпистемологически противоположен идее категоризации и ограничения знания, которая обычно используется в западных музеях и архивах.
	[ 33 ] Этой аналогии я обязана Дэну Хиксу, который в своей книге о британских музеях предлагает еще одну: «Ту роль, которую граница играет для нации, музей играет для империи».
всё это ещё перекликается с темой того, что звук в музее протекает в другие работы, что его невозможно (по-крайней мере пока что) как-то приручить, как-то ограничить
	Согласно словарному определению, звук – это «вибрации, которые путешествуют по воздуху или другой среде и которые человек или животное, когда эти вибрации достигают их, могут уловить ухом». Обращение к звуку как инструменту коммуникации и запоминания, увековечивания, особенно актуально в западно-африканском контексте. При помощи звука, его эха и ревербераций рассказываются и пересказываются истории через время и расстояние. Устные предания не неподвижны и неизменны, со временем они видоизменяются, и также прочно увязаны с настоящим. Природа такого знания «эллиптична и работает в режиме резонанса», [ 36 ] не зафиксирована во времени и пространстве, а переменчива.
